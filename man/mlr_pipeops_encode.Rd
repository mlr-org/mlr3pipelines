% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PipeOpEncode.R, R/PipeOpEncodeImpact.R
\docType{data}
\name{mlr_pipeops_encode}
\alias{mlr_pipeops_encode}
\alias{PipeOpEncode}
\alias{PipeOpEncodeLmer}
\title{PipeOpEncode}
\format{\code{\link{R6Class}} object inheriting from \code{\link{PipeOpTaskPreprocSimple}}/\code{\link{PipeOpTaskPreproc}}/\code{\link{PipeOp}}.}
\description{
Encodes columns of type \code{factor}, \code{character} and \code{ordered}.

Possible encodings are \code{"one-hot"} encoding, as well as encoding according to \code{stats::contr.helmert()}, \code{stats::contr.poly()},
\code{stats::contr.sum()} and \code{stats::contr.treatment()}.
Newly created columns are named via pattern \code{[column-name].[x]} where \code{x} is the respective factor level for \code{"one-hot"} and
\code{"treatment"} encoding, and an integer sequence otherwise.

Use the \code{\link{PipeOpTaskPreproc}} \code{$affect_columns} functionality to only encode a subset of columns, or only encode columns of a certain type.

Encodes columns of type \code{factor}, \code{character} and \code{ordered}.

PipeOpEncodeLmer() converts factor levels of each factorial column to the
estimated coefficients of a simple random intercept model.
Models are fitted with the glmer function of the lme4 package and are
of the type \code{target ~ 1 + (1 | factor)}.
If the task is a regression task, the numeric target
variable is used as dependent variable and the factor is used for grouping.
If the task is a classification task, the target variable is used as dependent variable
and the factor is used for grouping.
If the target variable is multiclass, for each level of the multiclass target variable,
binary "one vs. rest" models are fitted.

For training, multiple models can be estimated in a cross-validation scheme
to ensure that the same factor level does not always result in identical
values in the converted numerical feature.
For prediction, a global model (which was fitted on all observations
during training) is used for each factor.
New factor levels are converted to the value of the intercept coefficient
of the global model for prediction.
NAs are ignored by the CPO.

Use the \code{\link{PipeOpTaskPreproc}} \code{$affect_columns} functionality to only encode a subset of
columns, or only encode columns of a certain type.
}
\section{Construction}{
\preformatted{PipeOpEncode$new(id = "encode", param_vals = list())
}
\itemize{
\item \code{id} :: \code{character(1)}\cr
Identifier of resulting object, default \code{"encode"}.
\item \code{param_vals} :: named \code{list}\cr
List of hyperparameter settings, overwriting the hyperparameter settings that would otherwise be set during construction. Default \code{list()}.
}

\preformatted{PipeOpEncodeLmer$new(id = "encode", param_vals = list())
}

Identifier of resulting object, default \code{"encode"}.
\itemize{
\item \code{param_vals} :: named \code{list}\cr
List of hyperparameter settings, overwriting the hyperparameter settings that would
otherwise be set during construction. Default \code{list()}.
}
}

\section{Input and Output Channels}{

Input and output channels are inherited from \code{\link{PipeOpTaskPreproc}}.

The output is the input \code{\link[mlr3:Task]{Task}} with all affected \code{factor}, \code{character} or \code{ordered} parameters encoded according to the \code{method}
parameter.


Input and output channels are inherited from \code{\link{PipeOpTaskPreproc}}.

The output is the input \code{\link[mlr3:Task]{Task}} with all affected \code{factor}, \code{character} or
\code{ordered} parameters encoded according to the \code{method} parameter.
}

\section{State}{

The \code{$state} is a named \code{list} with the \code{$state} elements inherited from \code{\link{PipeOpTaskPreproc}}, as well as:
\itemize{
\item \code{constrasts} :: named \code{list} of \code{matrix}\cr
List of contrast matrices, one for each affected discrete feature. The rows of each matrix correspond to (training task) levels, the the
columns to the new columns that replace the old discrete feature. See \code{\link[stats:contrasts]{stats::contrasts}}.
}


The \code{$state} is a named \code{list} with the \code{$state} elements inherited from \code{\link{PipeOpTaskPreproc}}, as well as:
\itemize{
\item \code{target_levels} :: \code{character}\cr
Levels of the target columns.
\item \code{control} :: a named \code{list}\cr
List of coefficients learned via \code{glmer}
}
}

\section{Parameters}{

The parameters are the parameters inherited from \code{\link{PipeOpTaskPreproc}}, as well as:
\itemize{
\item \code{method}  :: \code{character(1)} \cr
Initialized to \code{"one-hot"}. One of:
\itemize{
\item \code{"one-hot"}: create a new column for each factor level.
\item \code{"treatment"}: create $n-1$ columns leaving out the first factor level of each factor variable (see \code{stats::contr.treatment()}).
\item \code{"helmert"}: create columns according to Helmert contrasts (see \code{stats::contr.helmert()}).
\item \code{"poly"}: create columns with contrasts based on orthogonal polynomials (see \code{stats::contr.poly()}).
\item \code{"sum"}: create columns with contrasts summing to zero, (see \code{stats::contr.sum()}).
}
}


\itemize{
\item \code{fast.optim}  :: \code{logical(1)} \cr
Initialized to \code{TRUE}.
If \dQuote{fast.optim} is \code{TRUE} (default), a faster (up to 50 percent)
optimizer from the nloptr package is used when fitting the lmer models.
This uses additional stopping criteria which can give suboptimal results.
}
}

\section{Internals}{

Uses the \code{\link[stats:contrasts]{stats::contrasts}} functions. This is relatively inefficient for features with a large number of levels.


Uses the \code{\link[lme4:glmer]{lme4::glmer}}. This is relatively inefficient for features with a large number of levels.
}

\section{Methods}{

Only methods inherited from \code{\link{PipeOpTaskPreprocSimple}}/\code{\link{PipeOpTaskPreproc}}/\code{\link{PipeOp}}.


Only methods inherited \code{\link{PipeOpTaskPreproc}}/\code{\link{PipeOp}}.
}

\examples{
library(mlr3)

task = TaskClassif$new("task",
  data.table::data.table(x = letters[1:3], y = letters[1:3]), "x")

poe = po("encode")

# poe is initialized with encoding: "one-hot"
poe$train(list(task))[[1]]$data()

# other kinds of encoding:
poe$param_set$values$method = "treatment"
poe$train(list(task))[[1]]$data()

poe$param_set$values$method = "helmert"
poe$train(list(task))[[1]]$data()

poe$param_set$values$method = "poly"
poe$train(list(task))[[1]]$data()

poe$param_set$values$method = "sum"
poe$train(list(task))[[1]]$data()
poe = mlr_pipeops$get("encodeLmer")

task = mlr3::TaskClassif$new("task",
  data.table::data.table(x = letters[1:3], y = letters[1:3]), "x")

poe$train(list(task))[[1]]$data()

}
\seealso{
Other PipeOps: \code{\link{PipeOpEnsemble}},
  \code{\link{PipeOpTaskPreproc}}, \code{\link{PipeOp}},
  \code{\link{mlr_pipeops_branch}},
  \code{\link{mlr_pipeops_chunk}},
  \code{\link{mlr_pipeops_classbalancing}},
  \code{\link{mlr_pipeops_classifavg}},
  \code{\link{mlr_pipeops_colapply}},
  \code{\link{mlr_pipeops_copy}},
  \code{\link{mlr_pipeops_featureunion}},
  \code{\link{mlr_pipeops_filter}},
  \code{\link{mlr_pipeops_histbin}},
  \code{\link{mlr_pipeops_ica}},
  \code{\link{mlr_pipeops_impute}},
  \code{\link{mlr_pipeops_kernelpca}},
  \code{\link{mlr_pipeops_learner}},
  \code{\link{mlr_pipeops_modelmatrix}},
  \code{\link{mlr_pipeops_mutate}},
  \code{\link{mlr_pipeops_nop}},
  \code{\link{mlr_pipeops_pca}},
  \code{\link{mlr_pipeops_regravg}},
  \code{\link{mlr_pipeops_scalemaxabs}},
  \code{\link{mlr_pipeops_scalerange}},
  \code{\link{mlr_pipeops_scale}},
  \code{\link{mlr_pipeops_select}},
  \code{\link{mlr_pipeops_smote}},
  \code{\link{mlr_pipeops_subsample}},
  \code{\link{mlr_pipeops_unbranch}},
  \code{\link{mlr_pipeops}}

Other PipeOps: \code{\link{PipeOpEnsemble}},
  \code{\link{PipeOpTaskPreproc}}, \code{\link{PipeOp}},
  \code{\link{mlr_pipeops_branch}},
  \code{\link{mlr_pipeops_chunk}},
  \code{\link{mlr_pipeops_classbalancing}},
  \code{\link{mlr_pipeops_classifavg}},
  \code{\link{mlr_pipeops_colapply}},
  \code{\link{mlr_pipeops_copy}},
  \code{\link{mlr_pipeops_featureunion}},
  \code{\link{mlr_pipeops_filter}},
  \code{\link{mlr_pipeops_impute}},
  \code{\link{mlr_pipeops_learner}},
  \code{\link{mlr_pipeops_mutate}},
  \code{\link{mlr_pipeops_nop}},
  \code{\link{mlr_pipeops_pca}},
  \code{\link{mlr_pipeops_regravg}},
  \code{\link{mlr_pipeops_scale}},
  \code{\link{mlr_pipeops_select}},
  \code{\link{mlr_pipeops_subsample}},
  \code{\link{mlr_pipeops_unbranch}},
  \code{\link{mlr_pipeops}}
}
\concept{PipeOps}
\keyword{datasets}
